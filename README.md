# Credit Default Prediction (HSE — Lab 4)

## Описание проекта

Цель проекта — построить модель классификации для прогнозирования факта невыполнения кредитных обязательств (`Credit Default`) на основе обучающего датасета.

Основная метрика качества — F1-score по классу 1 (просрочка по кредиту).

Требование задания: F1 > 0.5.

В задании встречается упоминание LinearRegression, однако для классификации и метрики F1 использована LogisticRegression как корректный аналог

---

## Данные

- Обучающая выборка: 7500 наблюдений, 17 признаков  
- Тестовая выборка: 2500 наблюдений, 16 признаков  
- Целевая переменная: `Credit Default`

### Распределение целевого класса

| Класс | Количество | Доля |
|--------|------------|------|
| 0 | 5387 | 71.83% |
| 1 | 2113 | 28.17% |

Наблюдается умеренный дисбаланс классов, поэтому в модели использована балансировка (`class_weight="balanced"`).

---

## Этапы разработки модели

### 1. Разведочный анализ данных

Проведён анализ:

- типов признаков (12 числовых, 4 категориальных);
- пропусков;
- распределения целевой переменной;
- выбросов в числовых признаках.

Выявлены значительные выбросы в признаках:

- Maximum Open Credit  
- Current Loan Amount  
- Current Credit Balance  
- Credit Score  

Для снижения влияния экстремальных значений применён клиппинг по 1% и 99% квантилям.

---

### Предобработка данных

Предобработка реализована через sklearn.Pipeline и ColumnTransformer, что обеспечивает одинаковые преобразования для обучающей и тестовой выборок.

Числовые признаки:
- клиппинг (ограничение выбросов по квантилям),
- заполнение пропусков медианой,
- стандартизация.

Категориальные признаки:
- заполнение пропусков наиболее частым значением,
- One-Hot Encoding.

Дополнительно удалены признаки с нулевой дисперсией.

После преобразований получено 44 итоговых признака.


---

### 3. Baseline модель

В качестве baseline использована `LogisticRegression` (scikit-learn) с балансировкой классов.

Разбиение данных:
- Train: 6000 наблюдений  
- Validation: 1500 наблюдений  

Результат на валидационной выборке:

F1-score (класс 1): 0.545

Confusion matrix:

|[[761 316]
 [146 277]]|



Требование F1 > 0.5 выполнено.

---

### 4. Подбор гиперпараметров

Для настройки модели использован `GridSearchCV` с 5-fold Stratified Cross Validation.

Подбирался параметр регуляризации C.

Лучший параметр:
C = 0.01

Средний F1 по кросс-валидации: 0.537

Baseline модель показала более высокий результат на валидационной выборке (0.545), поэтому она выбрана в качестве финальной.

---

### 5. Проверка переобучения

F1-score:

- Train: 0.547  
- Validation: 0.545  

Разница между обучающей и валидационной выборкой минимальна, что свидетельствует об отсутствии выраженного переобучения.

---

## Сравнение моделей

В рамках повышенного уровня сложности реализована самописная логистическая регрессия (градиентный спуск).

Результаты на валидационной выборке:

| Модель | F1 (validation) |
|--------|----------------|
| LogisticRegression (sklearn) | 0.545 |
| Custom Logistic Regression | 0.545 |

Для самописной модели оптимальный порог классификации составил 0.49.

Качество моделей сопоставимо, что подтверждает корректность реализации алгоритма.

---

## Прогноз на тестовом датасете

Финальная модель обучена на всей обучающей выборке и применена к тестовому датасету.

- Количество предсказаний: 2500  
- Порядок строк тестового датасета сохранён  
- Формат: один столбец `Credit Default`  

Сформированы файлы:

- `submit_sklearn.xls`
- `submit_custom.xls`

---

## Структура репозитория

|| HW_regression_TebenkovDM.ipynb
|| README.md
|| course_project_train.csv
|| course_project_test.csv
|| submit_sklearn.xls
|| submit_custom.xls


---

## Итог

- Реализован полный pipeline разработки ML-модели.
- Выполнено сравнение самописной логистической регрессии и реализации из scikit-learn.
- Использована метрика F1-score.
- Достигнуто требуемое качество F1 > 0.5.
- Проект опубликован в публичном репозитории GitHub.

Ссылка на github:
https://github.com/DmitryTeb/hse_lab4_home_task_tebenkov_dm.git
